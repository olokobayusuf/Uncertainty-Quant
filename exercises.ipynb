{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.5-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36564bit19053807de3b44f894d4c8758c328f67",
   "display_name": "Python 3.6.5 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bernoulli Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What is the sample space of the Bernoulli distribution?\n",
    "$$ \\Omega = \\{ 0, 1 \\} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. What is is corresponding probability measure?\n",
    "$$ \\mu(x) = \\left\\{\\begin{array}{lr} \\theta & \\textrm{when } x = 0 \\\\ 1 - \\theta & \\textrm{when } x = 1 \\end{array} \\right\\} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transformations on Random Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Suppose $X$ is uniform on $[0, 2\\pi]$. Find the density of $Y = \\sin X$.\n",
    "$$ P_X(x) = \\int_0^x p(t) dt $$\n",
    "$$ = \\int_0^x \\frac{1}{2\\pi} dt $$\n",
    "$$ = \\frac{1}{2\\pi} [t]_0^{x} $$\n",
    "$$ = \\frac{1}{2\\pi} x $$\n",
    "Then:\n",
    "$$ P_Y(y) = \\mu(Y \\leq y) = \\mu(\\sin X \\leq y) = \\mu(X \\leq \\arcsin y) = P_X(\\arcsin y) = \\frac{1}{2\\pi} \\arcsin y $$\n",
    "$$ \\therefore p_Y(y) = \\frac{1}{2 \\pi \\sqrt{1 - y^2}} $$\n",
    "**INCOMPLETE**. Answer should have $\\pi$ instead of $2\\pi$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Let $X_1$ and $X_2$ be two independent uniform distributions on $[0, 1]$.\n",
    "    - Find the density of $Y_1 = X_1 + X_2$\n",
    "\n",
    "    - Find the density of $Y_2 = X_1 - X_2$\n",
    "\n",
    "    - Find the density of $Y_3 = X_1 / X_2$\n",
    "\n",
    "    - Find the density of $Y_4 = \\max(X_1, X_2)$\n",
    "\n",
    "**INCOMPLETE**"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Expected Values and Moments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Find the mean and variance of a Gaussian random variable $X$ with a density:\n",
    "$$ p(x) = \\frac{1}{\\sqrt{2 \\pi}\\sigma} \\exp{ \\left(- \\frac{(x - \\mu)^2}{2 \\sigma^2 } \\right)} $$\n",
    "$$ \\mathbb{E}[p(x)] = \\int_{-\\infty}^{\\infty} x \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp{ \\left(- \\frac{(x - \\mu)^2}{2 \\sigma^2 } \\right)} dx $$\n",
    "$$ = \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\int_{-\\infty}^{\\infty} x \\exp{ \\left(- \\frac{(x - \\mu)^2}{2 \\sigma^2 } \\right)} dx $$\n",
    "Substituting:\n",
    "$$ t = \\frac{x - \\mu}{ \\sqrt{2} \\sigma} $$\n",
    "$$ x = \\sqrt{2} \\sigma t + \\mu $$\n",
    "$$ dx = \\sqrt{2} \\sigma dt $$\n",
    "We have:\n",
    "$$ = \\frac{\\sqrt{2} \\sigma}{\\sqrt{2 \\pi} \\sigma} \\int_{-\\infty}^{\\infty} (\\sqrt{2} \\sigma t + \\mu) \\exp(-t^2) dt $$\n",
    "$$ = \\frac{\\sqrt{2} \\sigma}{\\sqrt{2 \\pi} \\sigma} \\left( \\sqrt{2} \\sigma \\int_{-\\infty}^{\\infty} t \\exp(-t^2) dt + \\mu \\int_{-\\infty}^{\\infty} \\exp(-t^2) dt \\right) $$\n",
    "For the first term, we can compute the integral as:\n",
    "$$ \\int_{-\\infty}^{\\infty} t \\exp(-t^2) dt = \\left[ -\\frac{1}{2} \\exp(t^2) \\right]_{-\\infty}^{\\infty} = 0 $$\n",
    "For the second term, we have the following by polar integration:\n",
    "$$ \\int_{-\\infty}^{\\infty} \\exp(-t^2) dt = \\sqrt{\\pi} $$\n",
    "Hence we have:\n",
    "$$ = \\frac{\\sqrt{2} \\sigma}{\\sqrt{2 \\pi} \\sigma} ( \\mu \\sqrt{\\pi} ) $$\n",
    "$$ = \\mu $$\n",
    "For variance, we have:\n",
    "$$ Var(p) = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2 $$\n",
    "$$ = \\int_{-\\infty}^{\\infty} x^2 \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp{ \\left(- \\frac{(x - \\mu)^2}{2 \\sigma^2 } \\right)} dx - \\mu^2 $$\n",
    "Just as before, we substitute:\n",
    "$$ t = \\frac{x - \\mu}{ \\sqrt{2} \\sigma} $$\n",
    "$$ x = \\sqrt{2} \\sigma t + \\mu $$\n",
    "$$ dx = \\sqrt{2} \\sigma dt $$\n",
    "Hence we have:\n",
    "$$ = \\frac{\\sqrt{2} \\sigma}{\\sqrt{2 \\pi} \\sigma} \\int_{-\\infty}^{\\infty} (\\sqrt{2} \\sigma t + \\mu)^2 \\exp(-t^2) dt - \\mu^2 $$\n",
    "$$ = \\frac{1}{\\sqrt{\\pi}} \\left( 2 \\sigma^2 \\int_{-\\infty}^{\\infty} t^2 \\exp(-t^2) dt + 2 \\sqrt{2} \\mu \\sigma \\int_{-\\infty}^{\\infty} t \\exp(-t^2) + \\mu^2 \\int_{-\\infty}^{\\infty} \\exp(-t^2) \\right) - \\mu^2 $$\n",
    "Resolving the second and third terms as before:\n",
    "$$ = \\frac{2 \\sigma^2}{\\sqrt{\\pi}} \\int_{-\\infty}^{\\infty} t^2 \\exp(-t^2) dt + \\mu^2 - \\mu^2 $$\n",
    "$$ = \\frac{2 \\sigma^2}{\\sqrt{\\pi}} \\int_{-\\infty}^{\\infty} t^2 \\exp(-t^2) dt $$\n",
    "Now performing integration by parts with $u = t$ and $dv = t \\exp(-t^2)$, we have:\n",
    "$$ = \\frac{2 \\sigma^2}{\\sqrt{\\pi}} \\left( \\left[ -\\frac{t}{2} \\exp (-t^2) \\right]_{-\\infty}^{\\infty} - \\frac{1}{2} \\int_{-\\infty}^{\\infty} exp(-t^2) dt \\right) $$\n",
    "$$ = \\frac{\\sigma^2}{\\sqrt{\\pi}} \\int_{-\\infty}^{\\infty} exp(-t^2) dt $$\n",
    "$$ = \\frac{\\sigma^2}{\\sqrt{\\pi}} \\sqrt{\\pi} $$\n",
    "$$ = \\sigma^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Find the mean of the Cauchy distribution:\n",
    "$$ p(x) = \\frac{1}{\\pi (1 + x^2)} $$\n",
    "$$ \\mathbb{E}[p] = \\int_{-\\infty}^{\\infty} \\frac{x}{\\pi (1 + x^2)} dx = \\int_{-\\infty}^{0} \\frac{x}{\\pi (1 + x^2)} dx + \\int_{0}^{\\infty} \\frac{x}{\\pi (1 + x^2)} dx $$\n",
    "$$ = \\frac{1}{2\\pi} \\left( \\ln \\vert x^2 + 1 \\vert_{-\\infty}^{0} + \\ln \\vert x^2 + 1 \\vert_{0}^{\\infty} \\right) $$\n",
    "$$ = -\\infty + \\infty $$\n",
    "The integral is undefined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Find the mean and variance of the Binomial distribution:\n",
    "$$ b(x; n, p) = \\begin{pmatrix} n \\\\ x \\end{pmatrix} p^x (1-p)^{n - x} $$\n",
    "$$ \\mathbb{E}[X], X \\sim b(x; n, p) = \\sum_{x=0}^n x \\begin{pmatrix} n \\\\ x \\end{pmatrix} p^x (1-p)^{n - x} $$\n",
    "$$ = \\sum_{x=0}^n x \\frac{n!}{x! (n-x)!} p^x (1-p)^{n - x} $$\n",
    "$$ = 0 + \\sum_{x=1}^n \\frac{n!}{(x-1)! (n-x)!} p^x (1-p)^{n - x} $$\n",
    "Let $y = x - 1$ and $m = n - 1$, so that $x = y + 1$ and $n = m + 1$:\n",
    "$$ = \\sum_{y=0}^m \\frac{(m+1)!}{y! (m - y)!} p^{y+1} (1 - p)^{m - y} $$\n",
    "$$ = (m + 1) p \\sum_{y=0}^m \\frac{m!}{y! (m - y)!} p^y (1 - p)^{m - y} $$\n",
    "$$ = n p \\sum_{y=0}^m \\frac{m!}{y! (m - y)!} p^y (1 - p)^{m - y} $$\n",
    "$$ = np \\sum_{y=0}^m \\begin{pmatrix} m \\\\ y \\end{pmatrix} p^y (1 - p)^{m - y} $$\n",
    "But by the binomial theorem, we have:\n",
    "$$ = np (p + (1 - p))^m $$\n",
    "$$ \\mathbb{E}[X] = np $$\n",
    "We compute variance as:\n",
    "$$ Var(X) = \\mathbb{E}[X^2] - \\mathbb{E}[X]^2 $$\n",
    "$$ \\mathbb{E}[X^2] = \\sum_{x = 0}^n x^2 \\begin{pmatrix} n \\\\ x \\end{pmatrix} p^x (1-p)^{n - x} $$\n",
    "$$ = \\sum_{x = 0}^n x^2 \\frac{n!}{x! (n - x)!} p^x (1-p)^{n - x} $$\n",
    "$$ = \\sum_{x = 0}^n nx \\frac{n-1!}{(x-1)! (n - x)!} p^x (1-p)^{n - x} $$\n",
    "$$ = \\sum_{x = 0}^n nx \\begin{pmatrix} n - 1 \\\\ x - 1 \\end{pmatrix} p^x (1-p)^{n - x} $$\n",
    "$$ = 0 + \\sum_{x = 1}^n nx \\begin{pmatrix} n - 1 \\\\ x - 1 \\end{pmatrix} p^x (1-p)^{n - x} $$\n",
    "$$ = np \\sum_{x = 1}^n x \\begin{pmatrix} n - 1 \\\\ x - 1 \\end{pmatrix} p^{x-1} (1-p)^{n - x} $$\n",
    "Let $y = x - 1$ and $m = n - 1$, so that $x = y + 1$ and $n = m + 1$:\n",
    "$$ = np \\sum_{y=0}^m (y+1) \\begin{pmatrix} m \\\\ y \\end{pmatrix} p^{y} (1 - p)^{m - y} $$\n",
    "$$ = np \\left( \\sum_{y=0}^m y \\begin{pmatrix} m \\\\ y \\end{pmatrix} p^{y} (1 - p)^{m - y} + \\sum_{y=0}^m \\begin{pmatrix} m \\\\ y \\end{pmatrix} p^{y} (1 - p)^{m - y} \\right) $$\n",
    "$$ = np \\left( \\sum_{y=0}^m y \\begin{pmatrix} m \\\\ y \\end{pmatrix} p^{y} (1 - p)^{m - y} + 1 \\right)$$\n",
    "The first term is the expected value of the binomial distribution with respect to $y$ and $m$, hence we can recursively apply the proof from $\\mathbb{E}[X]$:\n",
    "$$ = np ( mp + 1 ) $$\n",
    "$$ = np ((n - 1)p + 1)$$\n",
    "$$ = np (np - p + 1) $$\n",
    "$$ \\mathbb{E}[X^2] = (np)^2 + np(1 - p) $$\n",
    "Therefore:\n",
    "$$ Var(X) = \\mathbb{E}[X^2] - \\mathbb{E}[X]^2 $$\n",
    "$$ = (np)^2 + np(1 - p) - (np)^2 $$\n",
    "$$ = np(1 - p) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Let $X$ be a random variable such that $\\mathbb{E}[|X|^m] \\leq AC^m$ for some positive constants $A$ and $C$, and all integers $m \\geq 0$. Show that $\\mu (|X| > C) = 0$.\n",
    "$$ X $$\n",
    "**INCOMPLETE**"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Joint Probability and Independence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Generate a sample of two random variables $X$ and $Y$ where $X$ and $Y$ are normal with a correlation $\\rho$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Correlation: [[1.         0.21478601]\n [0.21478601 1.        ]]\n"
    }
   ],
   "source": [
    "from numpy import array, corrcoef, stack\n",
    "from numpy.linalg import cholesky\n",
    "from numpy.random import normal\n",
    "\n",
    "N = 1000\n",
    "COR = 0.2\n",
    "# Generate samples\n",
    "samples = normal(loc=0., scale=1., size=(N, 2))\n",
    "transformation = array([\n",
    "    [1., COR],\n",
    "    [COR, 1.]\n",
    "])\n",
    "samples = samples @ cholesky(transformation) # Square root of transformation\n",
    "# Compute covariance\n",
    "rho = corrcoef(samples.T)\n",
    "print(f\"Correlation: {rho}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Conditional Probability and Conditional Expectation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Let $X$ and $Y$ be two random variables with $\\mathbb{E}[Y] = m$ and $\\mathbb{E}[Y^2] < \\infty$.\n",
    "- Show that the constant $c$ that minimizes $\\mathbb{E}[(Y - c)^2]$ is $c  = m$.\n",
    "\n",
    "$$ \\mathbb{E}[(Y - c)^2] = \\mathbb{E}[Y^2 - 2cY + c^2] $$\n",
    "$$ = \\mathbb{E}[Y] - 2c\\mathbb{E}[Y] + c^2 $$\n",
    "$$ = c^2 - 2cm + m $$\n",
    "$$ \\frac{\\delta}{\\delta c} = 2c - 2m $$\n",
    "$$ \\therefore c^* = m $$\n",
    "\n",
    "- Show that the random variable $f(X)$ that minimizes $\\mathbb{E}[(Y - f(X))^2\\ \\vert\\ X]$ is $f(X) = E[Y\\ \\vert\\ X]$.\n",
    "\n",
    "$$ \\mathbb{E}[(Y - f(x))^2] = \\mathbb{E}[Y^2 - 2f(x)Y + f^2(x)] $$\n",
    "$$ =\\mathbb{E}[Y^2 | X] - 2f(x) \\mathbb{E}[Y | X] + f^2(x) $$\n",
    "$$ \\frac{\\delta f(x)}{\\delta x} = -2\\mathbb{E}[Y | X] + 2f(x) $$\n",
    "$$ \\therefore f^*(x) = E[Y | X] $$\n",
    "\n",
    "- Show that the random variable $f(X)$ that minimizes $\\mathbb{E}[(Y - f(X))^2]$ is also $f(X) = E[Y\\ \\vert\\ X]$.\n",
    "**INCOMPLETE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Will you consider a coin asymmetric if after 1000 tosses, the number of heads equals 600?"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Maximum Likelihood Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Let $\\{ X_1, \\ldots, X_n \\}$ be i.i.d samples from $\\mathcal{U}(0., \\theta)$. Find $\\hat{\\theta}$ that maximizes the MLE.\n",
    "$$ \\mathcal{L}_n(\\theta) = \\prod_{i}^n p(x_i ; \\theta) = \\prod_{i}^n \\frac{1}{\\theta} = \\theta^{-n} $$\n",
    "$$ \\ln \\mathcal{L}_n(\\theta) = -n \\ln \\theta $$\n",
    "$$ \\frac{d}{d \\theta} = \\frac{-n}{\\theta} $$\n",
    "**INCOMPLETE**. Answer is max $X_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Show that the mean of $\\frac{\\delta}{\\delta x} \\ln p(x; \\theta) = 0$\n",
    "$$ \\mathbb{E} \\left[ \\frac{\\delta}{\\delta x} \\ln p(x; \\theta) \\right] = \\int_{-\\infty}^{\\infty} \\left( \\frac{\\delta}{\\delta x} \\ln p(x; \\theta) \\right) p(x; \\theta) dx $$\n",
    "$$ = \\int_{-\\infty}^{\\infty} \\frac{p'(x; \\theta)}{p(x; \\theta)} p(x; \\theta) dx $$\n",
    "$$ = \\int_{-\\infty}^{\\infty} p'(x; \\theta) dx $$\n",
    "$$ = \\frac{d}{dx} \\int_{-\\infty}^{\\infty} p(x; \\theta) $$\n",
    "$$ = \\frac{d}{dx} 1 $$\n",
    "$$ = 0 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Show that the mean of $\\frac{\\delta^2}{\\delta x^2} \\ln p(x; \\theta) = Var(\\frac{\\delta}{\\delta x} \\ln p(x; \\theta)) = I(\\theta)$\n",
    "**INCOMPLETE**"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Non-Parametric Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Show that for some empirical distribution, $\\mathbb{E}[\\hat{P}_n(x)] = P(x)$ and $Var(\\hat{P}_n(x)) = \\frac{P(x)(1-P(x))}{n}$\n",
    "$$ \\mathbb{E}(\\hat{P}_n(x)) = \\frac{1}{n} \\mathbb{E}[I(X_i \\leq x)] $$\n",
    "But since $I$ is an indicator function, we are simply taking the expected value of the Binomial distribution:\n",
    "$$ = \\frac{1}{n} nP(x) $$\n",
    "$$ = P(x) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. Derive the Nadaraya-Watson non-parametric regression technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17. Prove that the Monte Carlo estimator $\\hat{I}_n[f]$ is unbiased.\n",
    "$$ \\mathbb{E}(\\hat{I}_n[f]) = \\mathbb{E}\\left[ \\frac{1}{n} \\sum_i f(x_i) \\right] = \\frac{1}{n} \\sum_i^n \\mathbb{E}[f(x_i)] = \\mathbb{E}[f(x)] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18. Given the error of the Monte Carlo estimator:\n",
    "$$ e_n[f] = \\hat{I}_n[f] - I[f] $$\n",
    "Prove that from the Central Limit Theorem, as $n \\rightarrow \\infty$:\n",
    "    $$ e_n[f] \\approx \\sigma n^{\\frac{1}{2}} v$$\n",
    "Where $v \\sim \\mathcal{N}(0., 1.)$ and:\n",
    "$$ \\sigma^2 = \\left( \\frac{1}{n} \\int (f - I[f])^2 \\right) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19. Let $m_1$ and $m_2$ be the first and the second moments of $p(x)$. Also let $\\alpha_1$ and $\\alpha_2$ be the first and the second sample moments of a sample $\\{x_i\\}$.\n",
    "Then, instead of $\\{x_i\\}$, use the following transformed sample $\\{y_i\\}$\n",
    "that preserves the correct moments up to the second order:\n",
    "$$ y_i = (x_i - \\alpha_1)c + m_1$$\n",
    "Where:\n",
    "$$ c = \\sqrt{\\frac{m_2 - m_1^2}{\\alpha_2 - \\alpha_1^2}}$$\n",
    "Show that the first two sample moments of ${y_i}$ are equal to the true moments $m_1$ and $m_2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Chain Monte-Carlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20. Let $P$ be a matrix of transition probabilities of a homogeneous ergodic Markov chain on a finite state space such\n",
    "that $p_{ij} = p_{ji}$. Find its stationary distribution. We want a distribution $\\pi$ such that:\n",
    "$$ P \\pi = \\pi $$\n",
    "This corresponds to finding the eigenvector of the transition matrix with eigenvalue 1:\n",
    "$$ (I - P) \\pi = 0 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21. Consider a homogeneous Markov chain on the finite state space $\\Omega = \\{ 1, 2, \\ldots, r \\}$. Assume that all the elements of the transition matrix are positive. Prove that for any $k \\geq 0$ and any $x^0, x^1, \\ldots, x^k \\in \\Omega$:\n",
    "$$ \\mu(\\exists n,\\ x_n = x^0, x_{n+1}=x^1, \\ldots, x_{n+k}=x^k) = 1 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22. For a homogeneous Markov chains on a finite state space $\\Omega$ with transition matrix $P$ and initial distribution $\\pi_0$, find:\n",
    "$$ \\mu(x_n = x^1 \\vert\\ x_0 = x^2, x_{2n} = x^3) $$\n",
    "where $x^1, x^2, x^3 \\in \\Omega$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoothing with Orthogonal Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23. Given the estimator of the coefficient of a given orthogonal function for estimating density:\n",
    "$$ \\hat{\\beta}_j = \\frac{1}{n} \\sum_i^n \\phi_j(x_i) $$\n",
    "Prove that:\n",
    "$$ Var(\\beta_j) = \\frac{\\sigma^2_j}{n} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Differential Equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "24. Derive the Fokker-Planck equation for the following differential equations:\n",
    "- $du = au dt + \\sigma dw$\n",
    "- $du = -au dt$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kalman Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "25. Given the following SDE:\n",
    "$$ du = -\\gamma u dt + \\sigma dw $$\n",
    "What are the mean and variance of $u(t)$ if $u_0 \\sim \\mathcal{N}(m_0, \\sigma_0^2)$ where $m_0$ and $\\sigma_0^2$ are fixed constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}